{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geddamganesh/FMML-LAB-SESSION/blob/main/FMML_Module4_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjvepVoWOJU_"
      },
      "source": [
        "# FOUNDATIONS OF MODERN MACHINE LEARNING, IIIT Hyderabad\n",
        "# Module 4\n",
        "## Lab 4: Support Vector Machines\n",
        "### Module Coordinator: Jashn Arora\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjCAglTcNeGi",
        "outputId": "0a606ba4-92d2-4def-d72a-c7f71d5d1695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#Importing the necessary packages\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "import pandas\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-72af1f3b9182>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menable_iterative_imputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/usr/local/lib/python3.9/dist-packages/sklearn/metrics/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffq0iFPad5dq"
      },
      "source": [
        "The topic of classifier in today's lab, SVMs make for really good linear separators. Let us look at an example which has linearly separable data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "6wSo9Y7DWTth",
        "outputId": "cc8eb2f0-10b9-44bf-fdf9-589be0e7bf67"
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "ar = np.vstack(     [\\\n",
        "                    np.random.multivariate_normal(np.array([1, 1]), 1.5 * np.array([[2, -1], [-1, 2.0]]), size = 50, ),\\\n",
        "                    np.random.multivariate_normal(np.array([3, 3]), 2 * np.array([[0.75, -0.5], [-0.5, 0.75]]), size = 50, )\n",
        "                    ]\\\n",
        "              )\n",
        "\n",
        "testAr = np.vstack(   [\\\n",
        "                      np.random.multivariate_normal(np.array([1, 1]), np.array([[0.5, -0.25], [-0.25, 0.5]]), size = 500, ),\\\n",
        "                      np.random.multivariate_normal(np.array([3, 3]), np.array([[0.75, -0.5], [-0.5, 0.75]]), size = 500, )\n",
        "                      ]\\\n",
        "                  )\n",
        "testy = np.array([0] * int((testAr.shape[0]/2)) + [1] * int((testAr.shape[0]/2)))\n",
        "\n",
        "X = ar\n",
        "y = np.array([0] * int((ar.shape[0]/2)) + [1] * int((ar.shape[0]/2)))\n",
        "\n",
        "def plotDecisionBoundary(X, y, pair, clf):\n",
        "  x_min, x_max = X[:, pair[0]].min() - 1, X[:, pair[0]].max() + 1\n",
        "  y_min, y_max = X[:, pair[1]].min() - 1, X[:, pair[1]].max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                      np.arange(y_min, y_max, 0.1))\n",
        "  \n",
        "  y_pred = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  y_pred = y_pred.reshape(xx.shape)\n",
        "  plt.figure(figsize=(5,4))\n",
        "  plt.contourf(xx, yy, y_pred, alpha=0.4)\n",
        "  plt.scatter(X[:, pair[0]], X[:, pair[1]], c = y, s = 50, edgecolor='k')\n",
        "  # plt.legend()\n",
        "  plt.gcf().set_dpi(130)\n",
        "  plt.show()\n",
        "\n",
        "def boundaryExp() :\n",
        "  clf = svm.LinearSVC()\n",
        "  pair = [0, 1]\n",
        "  clf.fit(X[:, pair], y)\n",
        "  plotDecisionBoundary(X, y, pair, clf)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "boundaryExp()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a44bd7086026>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mboundaryExp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-a44bd7086026>\u001b[0m in \u001b[0;36mboundaryExp\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mplotDecisionBoundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a44bd7086026>\u001b[0m in \u001b[0;36mplotDecisionBoundary\u001b[0;34m(X, y, pair, clf)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vifDnoBfggg"
      },
      "source": [
        "## Intuitive introduction to SVMs:\n",
        "\n",
        "![SVM](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526288453/index3_souoaz.png)\n",
        "\n",
        "SVMs are an iterative approach of trying to find the optimal hyperplane that divides the multidimentional space into different classes present in the dataset.\n",
        "\n",
        "\n",
        "**Hyperplanes:** These are the decision planes that separate the objects of classes that we are trying to classify.\n",
        "\n",
        "**Support Vectors** : Support vectors are the points from dataset that are closest to the hyperplane that divides the dataset.\n",
        "\n",
        "**Margin**:  The gap between the closest support vectors from the different class along the direction perpendicular to the hyperplane. Simply put, it is the sum of perpendicular distance of the support vector of each class to the hyperplane.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0NxvgQziwTE"
      },
      "source": [
        "Let us try to fall back to the well known dataset and see how SVMs perform on the iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQldybfydNgN"
      },
      "source": [
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "irisData = pandas.DataFrame(\\\n",
        "    data = np.hstack((X,y.reshape(y.shape[0], 1), [[iris[\"target_names\"][int(classIdx)]] for classIdx in y])), \\\n",
        "    columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', \"Class\", \"ClassName\"])\n",
        "irisData.sample(n = 10, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOmnB77zn88d"
      },
      "source": [
        "clf = svm.LinearSVC()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy of the decision tree on the test set: \\n\\n{:.3f}\\n\\n\".format(accuracy_score(y_pred, y_test)))\n",
        "class_names = iris[\"target_names\"]\n",
        "print(\"The confusion matrix is : \")\n",
        "plot_confusion_matrix(clf, X_test, y_test, display_labels=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzbWs0CAoxuW"
      },
      "source": [
        "Now lets again try to see how does SVM perform when we give it just two of the features from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieCYm-K8olsj"
      },
      "source": [
        "clf = svm.LinearSVC()\n",
        "pair = [2, 3]\n",
        "clf.fit(X[:, pair], y)\n",
        "plotDecisionBoundary(X, y, [2, 3], clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_xJkLNxpCLq"
      },
      "source": [
        "clf = svm.LinearSVC()\n",
        "pair = [0, 1]\n",
        "clf.fit(X[:, pair], y)\n",
        "plotDecisionBoundary(X, y, pair, clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7iyfYePpaM6"
      },
      "source": [
        "#### Alas! We see that SVMs are not able to classify the data in the above experiment because the data is not **linearly separable**\n",
        "\n",
        "Thankfully, We have a neat trick up our sleeves that will help us to solve these problems. Let us take a look at a typical example that is used to illustrate this trick before we get back to the above dataset.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtn7FxSZqRj8"
      },
      "source": [
        "# The Kernel Trick\n",
        "\n",
        "The true potential of SVMs is unleashed when they are combined with kernels.\n",
        "\n",
        "## Kernels : An intuitive explanation\n",
        "\n",
        "Kernel methods are essentially counting on using the training data (say $i^{th}$ example $(x_i, y_i)$ ) itself in a more straightforward way and learning a corresponding weight ($w_i$) for that example. Rather than trying to learn a fixed set of parameters which is done typically.\n",
        "Depending on the kind of kernel used, we can virtually project the training data in a higher dimension to make it easier for the classifier to classify them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpzUIM1ppnxX"
      },
      "source": [
        "from sklearn.datasets.samples_generator import make_circles\n",
        "X, y = make_circles(200, factor=.1, noise=.1)\n",
        "\n",
        "clf = svm.SVC(kernel='linear').fit(X, y)\n",
        "\n",
        "plt.style.use(\"seaborn\")\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='tab20')\n",
        "plt.gcf().set_dpi(110)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cInt5fSty3w"
      },
      "source": [
        "plt.style.use(\"default\")\n",
        "clf = svm.LinearSVC()\n",
        "pair = [0, 1]\n",
        "clf.fit(X[:, pair], y)\n",
        "plotDecisionBoundary(X, y, [0, 1], clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJaPFAniusEA"
      },
      "source": [
        "However, if we artificially add another dimention to the dataset of the form:\n",
        "\n",
        "$z = x^2 + y^2$\n",
        "we can clearly see a hyperplane that can distinguish both the datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQamaPU8vfIz"
      },
      "source": [
        "Z = np.array([[i[0]**2 + i[1]**2] for i in X])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFi_pqMMvyPS"
      },
      "source": [
        "X_new = np.hstack((X, Z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t59SxC5L_BDY"
      },
      "source": [
        "import plotly.graph_objects as go\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JuoK_qjwPr_"
      },
      "source": [
        "fig = go.Figure(data = [go.Scatter3d(\n",
        "    x = X_new[:, 0],\n",
        "    y = X_new[:, 1],\n",
        "    z = X_new[:, 2],\n",
        "    mode = \"markers\",\n",
        "    marker = {\n",
        "        \"color\" : y,\n",
        "        \"line\": {\"width\" : 4, \"color\":'DarkSlateGrey'},\n",
        "        \"colorscale\": \"viridis\"},\n",
        ")])\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdGH5BF2xuab"
      },
      "source": [
        "That simple trick has helped us to get another dimension in which the data is linearly separable by a hyperplane (in this case, a 2d plane)\n",
        "\n",
        "---\n",
        "\n",
        "Now let us use the rbf kernel and use an SVM Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybfpMPLFyIiZ"
      },
      "source": [
        "plt.style.use(\"default\")\n",
        "clf = svm.SVC()\n",
        "pair = [0, 1]\n",
        "clf.fit(X[:, pair], y)\n",
        "plotDecisionBoundary(X, y, [0, 1], clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHwwqJzHyt23"
      },
      "source": [
        "Now let us get back to our original dataset of iris and see if this kernel trick has helped us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6RS1AGtyfYs"
      },
      "source": [
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy of the decision tree on the test set: \\n\\n{:.3f}\\n\\n\".format(accuracy_score(y_pred, y_test)))\n",
        "class_names = iris[\"target_names\"]\n",
        "print(\"The confusion matrix is : \")\n",
        "plot_confusion_matrix(clf, X_test, y_test, display_labels=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29evrc-jy0WO"
      },
      "source": [
        "Certainly, using a kernel has increased our accuracy on the iris dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to try out:\n",
        "- Try to run the same experiment after filtering different features, 2 at a time.\n",
        "- Using different kinds of kernels for the SVM among: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}"
      ],
      "metadata": {
        "id": "LteLWVYtYu8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1ST ANSWERE**"
      ],
      "metadata": {
        "id": "pyMqzvTafybg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.array([[i[0]**2 + i[1]**2] for i in X])\n",
        "Y = np.array([[i[0]**2 + i[1]**2] for i in X])"
      ],
      "metadata": {
        "id": "-eIyzhuVf16j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.hstack((X,Z)+(Y,Z))"
      ],
      "metadata": {
        "id": "lTw0L3zkgCVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"default\")\n",
        "clf = svm.SVC()\n",
        "pair = [0, 1]\n",
        "clf.fit(X[:, pair], y)\n",
        "plotDecisionBoundary(X, y, [0, 1], clf)"
      ],
      "metadata": {
        "id": "5qJkllOGgFwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AauG5wgjEy"
      },
      "source": [
        "End of Lab 4\n",
        "\n",
        "---\n",
        "\n",
        "Helpful References and sources:\n",
        "\n",
        "- https://datamites.com/blog/support-vector-machine-algorithm-svm-understanding-kernel-trick/\n",
        "- https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
        "- https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n"
      ]
    }
  ]
}